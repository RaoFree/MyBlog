title: WebAssembly学习笔记（二）初步理解LLVM架构编译器
date: 2020-02-01 20:03:43
---
---

# 一、虚拟机运行模式
以HotSpot为代表的主流商用虚拟机为例，HotSpot同时包含解释器和编译器。当程序需迅速启动并执行时，首先通过解释器进行解释执行，即逐行生成机器码的同时逐行执行；待程序运行后，再通过JIT编译器进行编译执行，即针对热点代码进行优化，一次性生成全部机器码后再执行。

## （一）何为热点代码
调用频率较高的方法与执行频率较高的循环体。

## （二）主流热点探测方式
<!--more-->
### 1.基于采样
虚拟机周期性地检查各个线程的栈顶，经常出现在栈顶的方法为“热点方法”，将触发JIT编译。	
该方法简单、易获取方法调用关系，但无法精确统计频率。

### 2.基于计数器（HotSpot使用）
虚拟机为每个方法建立方法计数器、为每个循环体建立回边计数器，统计执行次数。如执行次数超过阈值则为“热点方法”，将触发JIT编译。该方法复杂、无法获取方法调用关系，但可精确统计频率。

## （三）为何JIT编译器仅针对热点代码进行优化编译
### 1.原因一：执行速度
方法与循环体经JIT编译后得到机器码，再次调用时无需编译，可直接执行机器码，速度大幅提升。但在调用频率较低时，首次编译的开销仍无法被抵消忽略。

### 2.原因二：内存开销
编译后，机器码相对于中间代码IR将膨胀至10倍大小，内存开销较大，因此JIT编译不适用于全部中间代码IR。

## （四）HotSpot虚拟机在JDK1.7后的默认运行模式——分层编译（Tiered Compilation）
### 1.首先解释执行（第0层）
解释器不开启性能监控功能。

### 2.对于热点代码
（1）先进行C1编译（第1层 Client Compiler）
将中间代码IR编译为机器码，简单的局部优化，性能监控功能可选，以提升启动与执行速度。

（2）而后进行C2编译（第2层 Server Compiler）
将中间代码IR编译为机器码，耗时较长的全局优化，甚至根据性能监控信息进行激进优化，以提升优化效果。当激进优化假设不成立时，可通过逆优化（Deoptimization）退回到解释执行。

综上，同一代码可能被C1、C2多次编译。

# 二、编译器架构
## （一）传统编译器
分为三个阶段

### 1.前端（Frontend）
（1）输入：源代码
（2）操作：通过词法分析、语法分析、语义分析，构建针对语言的抽象语法树（AST），并生成中间代码IR
（3）输出：中间代码IR

### 2.优化器（Optimizer）

### 3.后端（Backend）
（1）输入：中间代码IR
（2）通过解释执行或编译执行的方式，生成机器码
（3）输出：机器码

## （二）LLVM架构的编译器
广义指LLVM编译器架构，包括前端、后端（含优化器）、库函数及模块；狭义指LLVM编译器架构的后端。
优于传统编译器的特点：不同的源代码语言，均能对应于同一种LLVM的中间代码LLVM IR（intermediate representation）。

### 1.LLVM架构的前端
通过词法分析、语法分析、语义分析，构建针对语言的抽象语法树（AST），并生成LLVM IR。

（1）主流前端GCC
GNU编译器，采用GPL协议，是多数开源软件的默认编译器，存在模块化程度低、与IDE配合较差的缺点。

（2）主流前端Clang
采用BSD协议，基于编译器后端LLVM，相比于GCC更轻量、编译速度更快、占用内存更小。

### 2.LLVM架构的后端
（1）优化器
只对LLVM IR进行优化。

（2）主流后端LLVM
将优化好的LLVM IR翻译为对应硬件平台的机器码。其中，生成机器码的方式有两种：

> A.解释执行
解释器将LLVM IR逐行翻译为机器码，同时逐行执行。生成的机器码不保存，因此无法复用。一次解释过程的耗时小于一次编译过程的耗时。
 
> B.JIT编译执行（Just In Time Compiler，即时编译器）
JIT编译器将LLVM IR一次性翻译为机器码并保存至内存中。再次调用相同方法时，可直接执行已保存的机器码。当直接执行内存中已保存的机器码时，耗时非常小。

### 3.Clang与LLVM的关系
Clang、LLVM是LLVM架构编译器的前端、后端组件。
{% asset_img llvm.png This is llvm.png %}
